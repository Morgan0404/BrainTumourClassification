{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.image as tf_image\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Conv2D, UpSampling2D, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "\n",
    "\n",
    "# DATA LOADING AND PREPROCESSING\n",
    "\n",
    "\n",
    "def load_unlabeled_images(root_folder, image_size=(224, 224)):\n",
    "   images_list = []\n",
    "   for split in [\"Train\", \"Test\"]:\n",
    "       split_dir = os.path.join(root_folder, split)\n",
    "       if not os.path.exists(split_dir):\n",
    "           print(f\"Warning: Directory {split_dir} not found. Skipping...\")\n",
    "           continue\n",
    "       for fn in os.listdir(split_dir):\n",
    "           if fn.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "               img_path = os.path.join(split_dir, fn)\n",
    "               try:\n",
    "                   image = cv2.imread(img_path)\n",
    "                   image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                   image = cv2.resize(image, image_size)\n",
    "                   image = image.astype(np.float32) / 255.0  # Normalize\n",
    "                   images_list.append(image)\n",
    "               except Exception as e:\n",
    "                   print(f\"[Skip] {img_path}: {e}\")\n",
    "   if len(images_list) == 0:\n",
    "       raise ValueError(\"No images were loaded. Check dataset structure.\")\n",
    "   return np.stack(images_list, axis=0)\n",
    "\n",
    "\n",
    "# MASKING FUNCTION\n",
    "\n",
    "\n",
    "def random_mask(image, mask_ratio=0.25):\n",
    "   \"\"\"Applies random masking to an image (lower ratio to preserve more details).\"\"\"\n",
    "   mask = tf.cast(tf.random.uniform(shape=tf.shape(image), minval=0, maxval=1) > mask_ratio, tf.float32)\n",
    "   return image * mask\n",
    "\n",
    "\n",
    "# EFFICIENTNETV2B0-BASED MAE WITH UNET-STYLE DECODER\n",
    "\n",
    "\n",
    "def build_mae_teacher_efficientnet_unet(input_shape=(224, 224, 3), latent_dim=512):\n",
    "   \"\"\"\n",
    "   Builds a Masked Autoencoder (MAE) using EfficientNetV2B0 as the encoder and a UNet-style decoder with skip connections.\n",
    "   \"\"\"\n",
    "   # Load EfficientNetV2B0 without the classification head\n",
    "   base_model = EfficientNetV2B0(include_top=False, input_shape=input_shape, weights=\"imagenet\")\n",
    "   base_model.trainable = True\n",
    "\n",
    "\n",
    "   # Define skip connections (adjust layer names as needed)\n",
    "   skip1 = base_model.get_layer(\"block2a_expand_activation\").output  # Expected shape: (None, 56, 56, channels) per error message\n",
    "   skip2 = base_model.get_layer(\"block3a_expand_activation\").output  # Expected shape: (None, 28, 28, channels)\n",
    "   skip3 = base_model.get_layer(\"block4a_expand_activation\").output  # Expected shape: (None, 14, 14, channels)\n",
    "\n",
    "\n",
    "   # Upsample skip connections to match target decoder sizes\n",
    "   skip2_up = UpSampling2D((2, 2), name=\"skip2_upsampled\")(skip2)   # From 28x28 to 56x56\n",
    "   skip1_up = UpSampling2D((2, 2), name=\"skip1_upsampled\")(skip1)   # From 56x56 to 112x112\n",
    "\n",
    "\n",
    "   # Encoder output (bottleneck)\n",
    "   encoder_output = base_model.output  # Expected shape: (None, 7, 7, ?)\n",
    "\n",
    "\n",
    "   # Bottleneck: flatten and reduce dimensionality\n",
    "   x = Flatten()(encoder_output)\n",
    "   x = Dense(latent_dim, activation=\"relu\")(x)\n",
    "   # Reproject to a feature map; assuming we start decoding at 7x7 with 256 channels\n",
    "   x = Dense(7 * 7 * 256, activation=\"relu\")(x)\n",
    "   x = Reshape((7, 7, 256))(x)\n",
    "\n",
    "\n",
    "   # Decoder\n",
    "   # Upsample from 7x7 to 14x14\n",
    "   x = UpSampling2D((2, 2), name=\"upsample1\")(x)  # Now 14x14\n",
    "   x = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", name=\"conv_dec1\")(x)\n",
    "  \n",
    "   # Upsample to 28x28 and concatenate with skip3\n",
    "   x = UpSampling2D((2, 2), name=\"upsample2\")(x)  # Now 28x28\n",
    "   x = Concatenate(name=\"concat_skip3\")([x, skip3])\n",
    "   x = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", name=\"conv_dec2\")(x)\n",
    "  \n",
    "   # Upsample to 56x56 and concatenate with skip2_up\n",
    "   x = UpSampling2D((2, 2), name=\"upsample3\")(x)  # Now 56x56\n",
    "   x = Concatenate(name=\"concat_skip2\")([x, skip2_up])\n",
    "   x = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", name=\"conv_dec3\")(x)\n",
    "  \n",
    "   # Upsample to 112x112 and concatenate with skip1_up\n",
    "   x = UpSampling2D((2, 2), name=\"upsample4\")(x)  # Now 112x112\n",
    "   x = Concatenate(name=\"concat_skip1\")([x, skip1_up])\n",
    "   x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", name=\"conv_dec4\")(x)\n",
    "  \n",
    "   # Upsample to 224x224\n",
    "   x = UpSampling2D((2, 2), name=\"upsample5\")(x)  # Now 224x224\n",
    "   x = Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\", name=\"conv_dec5\")(x)\n",
    "   outputs = Conv2D(3, (3, 3), activation=\"sigmoid\", padding=\"same\", name=\"decoder_output\")(x)\n",
    "\n",
    "\n",
    "   return Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "\n",
    "# PERFORMANCE METRICS\n",
    "\n",
    "\n",
    "def compute_ssim(original, reconstructed):\n",
    "   return tf.reduce_mean(tf_image.ssim(original, reconstructed, max_val=1.0))\n",
    "\n",
    "\n",
    "def compute_psnr(original, reconstructed):\n",
    "   mse = tf.keras.losses.MeanSquaredError()(original, reconstructed)\n",
    "   return 10.0 * tf.math.log(1.0 / mse) / tf.math.log(10.0)\n",
    "\n",
    "\n",
    "# HYBRID LOSS FUNCTION (MSE + SSIM)\n",
    "\n",
    "\n",
    "def hybrid_loss(original, reconstructed):\n",
    "   mse = tf.keras.losses.MeanSquaredError()(original, reconstructed)\n",
    "   ssim_loss = 1 - tf.reduce_mean(tf_image.ssim(original, reconstructed, max_val=1.0))\n",
    "   return 0.7 * mse + 0.3 * ssim_loss\n",
    "\n",
    "\n",
    "# MAE TRAINING FUNCTION\n",
    "\n",
    "\n",
    "def train_mae(root_folder, batch_size=16, epochs=15):\n",
    "   print(\"Loading unlabeled images...\")\n",
    "   images = load_unlabeled_images(root_folder)\n",
    "  \n",
    "   dataset = tf.data.Dataset.from_tensor_slices(images)\n",
    "   dataset = dataset.map(lambda x: (random_mask(x), x))\n",
    "   dataset = dataset.batch(batch_size).shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "   print(\"Building MAE model (UNet decoder + EfficientNetV2B0 encoder)...\")\n",
    "   mae_model = build_mae_teacher_efficientnet_unet(input_shape=(224, 224, 3), latent_dim=512)\n",
    "   mae_model.summary()\n",
    "\n",
    "\n",
    "   optimizer = Adam(learning_rate=1e-4)\n",
    "\n",
    "\n",
    "   history = {\"loss\": [], \"ssim\": [], \"psnr\": []}\n",
    "\n",
    "\n",
    "   print(\"Starting MAE training...\")\n",
    "   for epoch in range(epochs):\n",
    "       epoch_loss, epoch_ssim, epoch_psnr = 0, 0, 0\n",
    "       step_count = 0\n",
    "       for masked_x, original_x in dataset:\n",
    "           with tf.GradientTape() as tape:\n",
    "               reconstructed_x = mae_model(masked_x, training=True)\n",
    "               loss_val = hybrid_loss(original_x, reconstructed_x)\n",
    "           gradients = tape.gradient(loss_val, mae_model.trainable_variables)\n",
    "           optimizer.apply_gradients(zip(gradients, mae_model.trainable_variables))\n",
    "          \n",
    "           mse_val = tf.keras.losses.MeanSquaredError()(original_x, reconstructed_x)\n",
    "           ssim_val = tf.reduce_mean(tf_image.ssim(original_x, reconstructed_x, max_val=1.0))\n",
    "           psnr_val = 10.0 * tf.math.log(1.0 / mse_val) / tf.math.log(10.0)\n",
    "          \n",
    "           epoch_loss += loss_val.numpy()\n",
    "           epoch_ssim += ssim_val.numpy()\n",
    "           epoch_psnr += psnr_val.numpy()\n",
    "           step_count += 1\n",
    "\n",
    "\n",
    "       avg_loss = epoch_loss / step_count\n",
    "       avg_ssim = epoch_ssim / step_count\n",
    "       avg_psnr = epoch_psnr / step_count\n",
    "\n",
    "\n",
    "       history[\"loss\"].append(avg_loss)\n",
    "       history[\"ssim\"].append(avg_ssim)\n",
    "       history[\"psnr\"].append(avg_psnr)\n",
    "\n",
    "\n",
    "       print(f\"Epoch {epoch+1}/{epochs}, Hybrid Loss: {avg_loss:.4f}, SSIM: {avg_ssim:.4f}, PSNR: {avg_psnr:.4f}\")\n",
    "\n",
    "\n",
    "   mae_model.save(\"mae_teacher_model_improved.h5\")\n",
    "   print(\"Training complete\")\n",
    "   return mae_model, history, images\n",
    "\n",
    "\n",
    "# PLOTTING FUNCTIONS\n",
    "\n",
    "\n",
    "def plot_metrics(history):\n",
    "   epochs = range(1, len(history[\"loss\"]) + 1)\n",
    "   plt.figure(figsize=(12, 5))\n",
    "  \n",
    "   # Hybrid Loss Curve\n",
    "   plt.subplot(1, 3, 1)\n",
    "   plt.plot(epochs, history[\"loss\"], marker='o', label=\"Hybrid Loss\")\n",
    "   plt.xlabel(\"Epochs\")\n",
    "   plt.ylabel(\"Loss\")\n",
    "   plt.title(\"Loss Curve (MSE+SSIM)\")\n",
    "   plt.legend()\n",
    "   plt.grid()\n",
    "  \n",
    "   # SSIM Curve\n",
    "   plt.subplot(1, 3, 2)\n",
    "   plt.plot(epochs, history[\"ssim\"], marker='o', label=\"SSIM Score\", color=\"green\")\n",
    "   plt.xlabel(\"Epochs\")\n",
    "   plt.ylabel(\"SSIM\")\n",
    "   plt.title(\"SSIM Trend\")\n",
    "   plt.legend()\n",
    "   plt.grid()\n",
    "  \n",
    "   # PSNR Curve\n",
    "   plt.subplot(1, 3, 3)\n",
    "   plt.plot(epochs, history[\"psnr\"], marker='o', label=\"PSNR (dB)\", color=\"red\")\n",
    "   plt.xlabel(\"Epochs\")\n",
    "   plt.ylabel(\"PSNR\")\n",
    "   plt.title(\"PSNR Trend\")\n",
    "   plt.legend()\n",
    "   plt.grid()\n",
    "  \n",
    "   plt.show()\n",
    "   \n",
    "   \n",
    "def plot_reconstructions(model, images, num_samples=5):\n",
    "   sample_images = images[:num_samples]\n",
    "   masked_images = np.array([random_mask(img) for img in sample_images])\n",
    "   reconstructions = model.predict(masked_images)\n",
    "  \n",
    "   fig, axes = plt.subplots(num_samples, 3, figsize=(10, num_samples * 3))\n",
    "   for i in range(num_samples):\n",
    "       axes[i, 0].imshow(sample_images[i])\n",
    "       axes[i, 0].set_title(\"Original\")\n",
    "      \n",
    "       axes[i, 1].imshow(masked_images[i])\n",
    "       axes[i, 1].set_title(\"Masked\")\n",
    "      \n",
    "       axes[i, 2].imshow(reconstructions[i])\n",
    "       axes[i, 2].set_title(\"Reconstructed\")\n",
    "  \n",
    "   plt.tight_layout()\n",
    "   plt.show()\n",
    "\n",
    "\n",
    "# RUN TRAINING & EVALUATION\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   mae_model, training_history, dataset_images = train_mae(\"UnlabeledDataset\")\n",
    "   plot_metrics(training_history)\n",
    "   plot_reconstructions(mae_model, dataset_images, num_samples=5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
